{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load the Data and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "dataset_df = pd.read_csv(\"../data/generic_changed_dataset.csv\")\n",
    "le = LabelEncoder()\n",
    "type_encoded = le.fit_transform(dataset_df[\"type\"])  # Now each type is a unique int\n",
    "num_types = len(le.classes_)  # Number of unique types\n",
    "print(num_types)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 768)\n",
      "(2000, 384)\n"
     ]
    }
   ],
   "source": [
    "# Load embeddings without training it again from the dataset_df\n",
    "X_distil_bert = np.load(\"distil_bert_embeddings.npy\")\n",
    "print(X_distil_bert.shape)\n",
    "X_sbert = np.load(\"sbert_embeddings.npy\")\n",
    "print(X_sbert.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Embedding Type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Train Shape",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Val Shape",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "Test Shape",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "1345b347-2d5d-4be6-b2d5-4ab328afec67",
       "rows": [
        [
         "0",
         "DistilBERT",
         "(800, 768)",
         "(600, 768)",
         "(600, 768)"
        ],
        [
         "1",
         "SBERT",
         "(800, 384)",
         "(600, 384)",
         "(600, 384)"
        ]
       ],
       "shape": {
        "columns": 4,
        "rows": 2
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Embedding Type</th>\n",
       "      <th>Train Shape</th>\n",
       "      <th>Val Shape</th>\n",
       "      <th>Test Shape</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DistilBERT</td>\n",
       "      <td>(800, 768)</td>\n",
       "      <td>(600, 768)</td>\n",
       "      <td>(600, 768)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SBERT</td>\n",
       "      <td>(800, 384)</td>\n",
       "      <td>(600, 384)</td>\n",
       "      <td>(600, 384)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Embedding Type Train Shape   Val Shape  Test Shape\n",
       "0     DistilBERT  (800, 768)  (600, 768)  (600, 768)\n",
       "1          SBERT  (800, 384)  (600, 384)  (600, 384)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_BERT_train, X_BERT_test, y1_BERT_train, y1_BERT_test, y2_BERT_train, y2_BERT_test = train_test_split(X_distil_bert, dataset_df[\"labels\"], type_encoded, test_size=0.6, random_state=42) # Train split\n",
    "X_BERT_val, X_BERT_test, y1_BERT_val, y1_BERT_test, y2_BERT_val, y2_BERT_test = train_test_split(X_BERT_test, y1_BERT_test, y2_BERT_test, test_size=0.5, random_state=42) # Validation and test split\n",
    "\n",
    "X_SBERT_train, X_SBERT_test, y1_SBERT_train, y1_SBERT_test, y2_SBERT_train, y2_SBERT_test = train_test_split(X_sbert, dataset_df[\"labels\"], type_encoded, test_size=0.6, random_state=42) # Train split\n",
    "X_SBERT_val, X_SBERT_test, y1_SBERT_val, y1_SBERT_test, y2_SBERT_val, y2_SBERT_test = train_test_split(X_SBERT_test, y1_SBERT_test, y2_SBERT_test, test_size=0.5, random_state=42) # Validation and test split\n",
    "\n",
    "\n",
    "# Put the shapes into a table for easy comparison\n",
    "pd.DataFrame(\n",
    "    {\n",
    "        \"Embedding Type\": [\n",
    "            \"DistilBERT\",\n",
    "            \"SBERT\",\n",
    "        ],\n",
    "        \"Train Shape\": [\n",
    "            X_BERT_train.shape,\n",
    "            X_SBERT_train.shape,\n",
    "        ],\n",
    "        \"Val Shape\": [\n",
    "            X_BERT_val.shape,\n",
    "            X_SBERT_val.shape,\n",
    "        ],\n",
    "        \"Test Shape\": [\n",
    "            X_BERT_test.shape,\n",
    "            X_SBERT_test.shape,\n",
    "        ],\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_data = {\n",
    "    \"DistilBERT\": {\n",
    "        \"X_train\": X_BERT_train,\n",
    "        \"X_val\": X_BERT_val,\n",
    "        \"X_test\": X_BERT_test,\n",
    "        \"y1_train\": y1_BERT_train,\n",
    "        \"y1_val\": y1_BERT_val,\n",
    "        \"y1_test\": y1_BERT_test,\n",
    "        \"y2_train\": y2_BERT_train,\n",
    "        \"y2_val\": y2_BERT_val,\n",
    "        \"y2_test\": y2_BERT_test,\n",
    "    },\n",
    "    \"SBERT\": {\n",
    "        \"X_train\": X_SBERT_train,\n",
    "        \"X_val\": X_SBERT_val,\n",
    "        \"X_test\": X_SBERT_test,\n",
    "        \"y1_train\": y1_SBERT_train,\n",
    "        \"y1_val\": y1_SBERT_val,\n",
    "        \"y1_test\": y1_SBERT_test,\n",
    "        \"y2_train\": y2_SBERT_train,\n",
    "        \"y2_val\": y2_SBERT_val,\n",
    "        \"y2_test\": y2_SBERT_test,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    "    f1_score,\n",
    "    confusion_matrix,\n",
    ")\n",
    "import scipy\n",
    "\n",
    "\n",
    "class MultiTaskDataset(Dataset):\n",
    "    def __init__(self, embedding, labels, types):\n",
    "        self.X = torch.tensor(embedding, dtype=torch.float32)\n",
    "        # For binary task, we use float labels\n",
    "        self.labels = torch.tensor(\n",
    "            labels.values if hasattr(labels, \"values\") else labels, dtype=torch.float32\n",
    "        )\n",
    "        # For multi-class, targets should be long (integer encoded)\n",
    "        self.types = torch.tensor(\n",
    "            types.values if hasattr(types, \"values\") else types, dtype=torch.long\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.X[idx], self.labels[idx], self.types[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiTaskNet(nn.Module):\n",
    "    def __init__(self, feature_dimension, num_types):\n",
    "        super(MultiTaskNet, self).__init__()\n",
    "        # Shared layers\n",
    "        self.shared = nn.Sequential(\n",
    "            nn.Linear(feature_dimension, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),  # Regularization for preventing overfitting\n",
    "        )\n",
    "        # Head for binary scam label prediction\n",
    "        self.label_head = nn.Linear(512, 1)  # output logit for binary classification\n",
    "\n",
    "        # Head for multi-class scam type prediction\n",
    "        self.type_head = nn.Linear(512, num_types)\n",
    "\n",
    "    def forward(self, x):\n",
    "        shared_rep = self.shared(x)\n",
    "        # For binary classification, weâ€™ll use BCEWithLogitsLoss, so no sigmoid here.\n",
    "        label_logits = self.label_head(shared_rep)\n",
    "        # For type classification, output logits (to be used with CrossEntropyLoss)\n",
    "        type_logits = self.type_head(shared_rep)\n",
    "        return label_logits, type_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "class MutltiTaskModel:\n",
    "    def __init__(self, X_train, y1_train, y2_train, num_types, batch_size=32, lr=1e-3):\n",
    "        self.model = MultiTaskNet(X_train.shape[1], num_types)\n",
    "\n",
    "        # Determine device (cuda, mps, or cpu)\n",
    "        if torch.cuda.is_available():\n",
    "            self.device = torch.device(\"cuda\")\n",
    "        elif torch.backends.mps.is_available():\n",
    "            self.device = torch.device(\"mps\")\n",
    "        else:\n",
    "            self.device = torch.device(\"cpu\")\n",
    "        self.model.to(self.device)\n",
    "\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
    "        self.criterion_label = nn.BCEWithLogitsLoss()\n",
    "        self.criterion_type = nn.CrossEntropyLoss()\n",
    "        self.batch_size = batch_size\n",
    "        self.input_dim = X_train.shape[1]\n",
    "\n",
    "        # Create DataLoader for training\n",
    "        self.train_dataset = MultiTaskDataset(X_train, y1_train, y2_train)\n",
    "        self.train_loader = DataLoader(\n",
    "            self.train_dataset, batch_size=batch_size, shuffle=True\n",
    "        )\n",
    "\n",
    "        # Lists to store losses for plotting\n",
    "        self.train_label_losses = []\n",
    "        self.train_type_losses = []\n",
    "\n",
    "        # For saving the best model\n",
    "        self.best_model_weights = None\n",
    "\n",
    "    def summary(self):\n",
    "        \"\"\"\n",
    "        Prints the model summary.\n",
    "        \"\"\"\n",
    "        self.model.to(\"cpu\")\n",
    "        summary(self.model, (self.batch_size, self.input_dim))\n",
    "        self.model.to(self.device)\n",
    "\n",
    "    def train(self, num_epochs):\n",
    "        best_loss = float(\"inf\")\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            self.model.train()\n",
    "            total_loss_label = 0.0\n",
    "            total_loss_type = 0.0\n",
    "            num_batches = 0\n",
    "\n",
    "            for inputs, labels, types in self.train_loader:\n",
    "                inputs, labels, types = (\n",
    "                    inputs.to(self.device),\n",
    "                    labels.to(self.device),\n",
    "                    types.to(self.device),\n",
    "                )\n",
    "\n",
    "                self.optimizer.zero_grad()\n",
    "                label_logits, type_logits = self.model(inputs)\n",
    "\n",
    "                loss_label = self.criterion_label(label_logits.view(-1), labels)\n",
    "                loss_type = self.criterion_type(type_logits, types)\n",
    "\n",
    "                loss = loss_label + loss_type\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "                total_loss_label += loss_label.item()\n",
    "                total_loss_type += loss_type.item()\n",
    "                num_batches += 1\n",
    "\n",
    "            # Calculate average loss for the epoch\n",
    "            avg_loss_label = total_loss_label / num_batches\n",
    "            avg_loss_type = total_loss_type / num_batches\n",
    "            total_loss = avg_loss_label + avg_loss_type\n",
    "\n",
    "            # Store losses for plotting\n",
    "            self.train_label_losses.append(avg_loss_label)\n",
    "            self.train_type_losses.append(avg_loss_type)\n",
    "\n",
    "            if epoch % 10 == 0:\n",
    "                print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "                print(f\"Average Loss (Label): {avg_loss_label:.4f}\")\n",
    "                print(f\"Average Loss (Type): {avg_loss_type:.4f}\")\n",
    "                print(f\"Total Loss: {total_loss:.4f}\\n\")\n",
    "\n",
    "            # Save best model weights\n",
    "            if total_loss < best_loss:\n",
    "                best_loss = total_loss\n",
    "                self.best_model_weights = self.model.state_dict()\n",
    "\n",
    "        print(\"Training complete.\")\n",
    "\n",
    "    def plot_losses(self):\n",
    "        \"\"\"\n",
    "        Plots the losses for label and type predictions during training.\n",
    "        \"\"\"\n",
    "        plt.figure(figsize=(10, 5))\n",
    "        plt.plot(self.train_label_losses, label=\"Label Loss\")\n",
    "        plt.plot(self.train_type_losses, label=\"Type Loss\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.title(\"Training Losses\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Makes predictions for the given inputs X.\n",
    "\n",
    "        Parameters:\n",
    "            X (numpy array or tensor): Input features.\n",
    "\n",
    "        Returns:\n",
    "            tuple: (predicted_label, predicted_type) where predicted_label is the binary prediction (0 or 1)\n",
    "                   and predicted_type is the predicted class for multi-class task.\n",
    "        \"\"\"\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            inputs = torch.tensor(X, dtype=torch.float32).to(self.device)\n",
    "            label_logits, type_logits = self.model(inputs)\n",
    "            label_pred = (\n",
    "                (torch.sigmoid(label_logits) >= 0.5).cpu().numpy().astype(int)\n",
    "            )  # Convert to 0 or 1 instead of floating point from sigmoid\n",
    "            type_pred = torch.argmax(type_logits, dim=1).cpu().numpy()\n",
    "\n",
    "        return label_pred, type_pred\n",
    "\n",
    "    def evaluate(self, X, y1, y2):\n",
    "        \"\"\"\n",
    "        Evaluates the model on the provided dataset and computes various performance metrics.\n",
    "\n",
    "        Parameters:\n",
    "            X (array-like): Input features.\n",
    "            y1 (array-like): True labels for binary classification.\n",
    "            y2 (array-like): True labels for multi-class classification.\n",
    "\n",
    "        Returns:\n",
    "            tuple: A nested tuple containing:\n",
    "                - accuracy (float): Overall accuracy of the model.\n",
    "                - precision (float): Precision score.\n",
    "                - recall (float): Recall score.\n",
    "                - f1 (float): F1 score.\n",
    "                - conf_matrix (array-like): Confusion matrix.\n",
    "                - class_report (str): Text summary of the precision, recall, and f1-score for each class.\n",
    "        \"\"\"\n",
    "        y1_pred, y2_pred = self.predict(X)\n",
    "\n",
    "        # Binary classification metrics\n",
    "        accuracy_label = accuracy_score(y1, y1_pred)\n",
    "        precision_label = precision_score(y1, y1_pred, zero_division=0)\n",
    "        recall_label = recall_score(y1, y1_pred, zero_division=0)\n",
    "        f1_label = f1_score(y1, y1_pred, zero_division=0)\n",
    "        conf_matrix_label = confusion_matrix(y1, y1_pred)\n",
    "\n",
    "        # Multi-class classification metrics\n",
    "        accuracy_type = accuracy_score(y2, y2_pred)\n",
    "        precision_type = precision_score(\n",
    "            y2, y2_pred, average=\"weighted\", zero_division=0\n",
    "        )\n",
    "        recall_type = recall_score(y2, y2_pred, average=\"weighted\", zero_division=0)\n",
    "        f1_type = f1_score(y2, y2_pred, average=\"weighted\", zero_division=0)\n",
    "        conf_matrix_type = confusion_matrix(y2, y2_pred)\n",
    "\n",
    "        return (\n",
    "            accuracy_label,\n",
    "            precision_label,\n",
    "            recall_label,\n",
    "            f1_label,\n",
    "            conf_matrix_label,\n",
    "        ), (accuracy_type, precision_type, recall_type, f1_type, conf_matrix_type)\n",
    "\n",
    "    def plot_confusion_matrix(self, X, y1, y2, labels):\n",
    "        \"\"\"\n",
    "        Plots the confusion matrix for the model's predictions.\n",
    "\n",
    "        Parameters:\n",
    "            X (array-like): Input features.\n",
    "            y1 (array-like): True labels for binary classification.\n",
    "            y2 (array-like): True labels for multi-class classification.\n",
    "            labels (list): List of label names to be used in the plot axes.\n",
    "        \"\"\"\n",
    "        y1_pred, y2_pred = self.predict(X)\n",
    "\n",
    "        plt.figure(figsize=(12, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        sns.heatmap(\n",
    "            confusion_matrix(y1, y1_pred),\n",
    "            annot=True,\n",
    "            fmt=\"d\",\n",
    "            cmap=\"Blues\",\n",
    "            xticklabels=[\"Not Scam\", \"Scam\"],\n",
    "            yticklabels=[\"Not Scam\", \"Scam\"],\n",
    "        )\n",
    "        plt.xlabel(\"Predicted Labels\")\n",
    "        plt.ylabel(\"True Labels\")\n",
    "        plt.title(\"Binary Classification\")\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        sns.heatmap(\n",
    "            confusion_matrix(y2, y2_pred),\n",
    "            annot=True,\n",
    "            fmt=\"d\",\n",
    "            cmap=\"Blues\",\n",
    "            xticklabels=labels,\n",
    "            yticklabels=labels,\n",
    "        )\n",
    "        plt.xlabel(\"Predicted Labels\")\n",
    "        plt.ylabel(\"True Labels\")\n",
    "        plt.title(\"Multi-Class Classification\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tune the hyperparameters of the model to get the best performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame(columns=[\n",
    "    \"Algorithm\",\n",
    "    \"Embedding\",\n",
    "    \"Type\", \n",
    "    \"y1_Accuracy\",\n",
    "    \"y1_Precision\",\n",
    "    \"y1_Recall\",\n",
    "    \"y1_F1_Score\",\n",
    "    \"y2_Accuracy\", \n",
    "    \"y2_Precision\",\n",
    "    \"y2_Recall\",\n",
    "    \"y2_F1_Score\"\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVM for y1 with SBERT embeddings...\n",
      "Best parameters for y1: {'estimator__C': 10, 'estimator__gamma': 'scale', 'estimator__kernel': 'rbf'}\n",
      "Best F1 Score for y1: 0.9837\n",
      "\n",
      "Training SVM for y2 with SBERT embeddings...\n",
      "Best parameters for y2: {'estimator__C': 10, 'estimator__gamma': 'scale', 'estimator__kernel': 'rbf'}\n",
      "Best F1 Score for y2: 0.9721\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/p_/98jdrnfd7yg93vdc0hn1gzb80000gn/T/ipykernel_49293/2008415818.py:83: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  result = pd.concat([result, new_row], ignore_index=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Wrap SVC in a OneVsRestClassifier for multi-class problems\n",
    "ovr_svc = OneVsRestClassifier(SVC())\n",
    "\n",
    "# Define parameter grid with prefix 'estimator__'\n",
    "param_grid = {\n",
    "    \"estimator__C\": [0.1, 1, 10],\n",
    "    \"estimator__kernel\": [\"linear\", \"rbf\"],\n",
    "    \"estimator__gamma\": [\"scale\", \"auto\"],\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV with the one-vs-rest classifier\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=ovr_svc, param_grid=param_grid, cv=5, scoring=\"f1_weighted\"\n",
    ")\n",
    "\n",
    "# Fit grid search on the training data on both y1 and y2 (binary and multi-class)\n",
    "svm_results = {}\n",
    "for i in range(2):\n",
    "    print(f\"Training SVM for y{i+1} with SBERT embeddings...\")\n",
    "    grid_search.fit(\n",
    "        embedding_data[\"SBERT\"][\"X_train\"], embedding_data[\"SBERT\"][f\"y{i+1}_train\"]\n",
    "    )\n",
    "\n",
    "    # Get the best parameters and the corresponding accuracy\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "\n",
    "    print(f\"Best parameters for y{i+1}: {best_params}\")\n",
    "    print(f\"Best F1 Score for y{i+1}: {best_score:.4f}\\n\")\n",
    "\n",
    "    # Evaluate the model on the test set\n",
    "    y_pred = grid_search.predict(embedding_data[\"SBERT\"][f\"X_test\"])\n",
    "    svm_results[f\"y{i+1}_Accuracy\"] = accuracy_score(\n",
    "        embedding_data[\"SBERT\"][f\"y{i+1}_test\"], y_pred\n",
    "    )\n",
    "    if i == 1:\n",
    "        average_type = \"weighted\"\n",
    "    else:\n",
    "        average_type = \"binary\"\n",
    "    svm_results[f\"y{i+1}_Precision\"] = precision_score(\n",
    "        embedding_data[\"SBERT\"][f\"y{i+1}_test\"],\n",
    "        y_pred,\n",
    "        average=average_type,\n",
    "        zero_division=0,\n",
    "    )\n",
    "    svm_results[f\"y{i+1}_Recall\"] = recall_score(\n",
    "        embedding_data[\"SBERT\"][f\"y{i+1}_test\"],\n",
    "        y_pred,\n",
    "        average=average_type,\n",
    "        zero_division=0,\n",
    "    )\n",
    "    svm_results[f\"y{i+1}_F1_Score\"] = f1_score(\n",
    "        embedding_data[\"SBERT\"][f\"y{i+1}_test\"],\n",
    "        y_pred,\n",
    "        average=average_type,\n",
    "        zero_division=0,\n",
    "    )\n",
    "\n",
    "# Create a new DataFrame for the new row\n",
    "new_row = pd.DataFrame(\n",
    "    [\n",
    "        {\n",
    "            \"Algorithm\": \"SVM\",\n",
    "            \"Embedding\": \"SBERT\",\n",
    "            \"Type\": \"Test Set\",\n",
    "            \"y1_Accuracy\": svm_results[\"y1_Accuracy\"],\n",
    "            \"y1_Precision\": svm_results[\"y1_Precision\"],\n",
    "            \"y1_Recall\": svm_results[\"y1_Recall\"],\n",
    "            \"y1_F1_Score\": svm_results[\"y1_F1_Score\"],\n",
    "            \"y2_Accuracy\": svm_results[\"y2_Accuracy\"],\n",
    "            \"y2_Precision\": svm_results[\"y2_Precision\"],\n",
    "            \"y2_Recall\": svm_results[\"y2_Recall\"],\n",
    "            \"y2_F1_Score\": svm_results[\"y2_F1_Score\"],\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Concatenate the new row with the existing DataFrame\n",
    "result = pd.concat([result, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Multi-Task Model for DistilBERT...\n",
      "Training Multi-Task Model for SBERT...\n"
     ]
    }
   ],
   "source": [
    "# Initialize the multi_task_model for the different embeddings\n",
    "multi_task_models = {}\n",
    "\n",
    "for embedding, data in embedding_data.items():\n",
    "    print(f\"Training Multi-Task Model for {embedding}...\")\n",
    "\n",
    "    # Convert sparse matrix to dense if needed\n",
    "    X_train = (\n",
    "        data[\"X_train\"].toarray()\n",
    "        if scipy.sparse.issparse(data[\"X_train\"])\n",
    "        else data[\"X_train\"]\n",
    "    )\n",
    "\n",
    "    multi_task_model = MutltiTaskModel(\n",
    "        X_train, data[\"y1_train\"], data[\"y2_train\"], num_types=len(le.classes_)\n",
    "    )\n",
    "\n",
    "    # Add the model to the dictionary\n",
    "    multi_task_models[embedding] = multi_task_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 20:15:33,550\tINFO worker.py:1841 -- Started a local Ray instance.\n",
      "2025-03-10 20:15:34,076\tINFO tune.py:253 -- Initializing Ray automatically. For cluster usage or custom Ray initialization, call `ray.init(...)` before `tune.run(...)`.\n",
      "2025-03-10 20:15:34,078\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "2025-03-10 20:15:34,104\tINFO tensorboardx.py:193 -- pip install \"ray[tune]\" to see TensorBoard files.\n",
      "2025-03-10 20:15:34,104\tWARNING callback.py:136 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-03-10 20:16:02</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:28.69        </td></tr>\n",
       "<tr><td>Memory:      </td><td>10.4/16.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 1.0/8 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name        </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  num_epochs</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  combined_f1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>lambda_5e0dd_00000</td><td>TERMINATED</td><td>127.0.0.1:49351</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">0.00218759 </td><td style=\"text-align: right;\">          90</td><td style=\"text-align: right;\">    90</td><td style=\"text-align: right;\">        24.696  </td><td style=\"text-align: right;\">     0.968847</td></tr>\n",
       "<tr><td>lambda_5e0dd_00001</td><td>TERMINATED</td><td>127.0.0.1:49358</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">0.000786052</td><td style=\"text-align: right;\">          40</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         9.50231</td><td style=\"text-align: right;\">     0.963778</td></tr>\n",
       "<tr><td>lambda_5e0dd_00002</td><td>TERMINATED</td><td>127.0.0.1:49355</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">0.00119674 </td><td style=\"text-align: right;\">          60</td><td style=\"text-align: right;\">    60</td><td style=\"text-align: right;\">        12.2965 </td><td style=\"text-align: right;\">     0.966345</td></tr>\n",
       "<tr><td>lambda_5e0dd_00003</td><td>TERMINATED</td><td>127.0.0.1:49356</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">1.10158e-05</td><td style=\"text-align: right;\">          80</td><td style=\"text-align: right;\">    80</td><td style=\"text-align: right;\">        10.5472 </td><td style=\"text-align: right;\">     0.609781</td></tr>\n",
       "<tr><td>lambda_5e0dd_00004</td><td>TERMINATED</td><td>127.0.0.1:49352</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">0.00119505 </td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         7.4678 </td><td style=\"text-align: right;\">     0.966367</td></tr>\n",
       "<tr><td>lambda_5e0dd_00005</td><td>TERMINATED</td><td>127.0.0.1:49357</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">0.00168293 </td><td style=\"text-align: right;\">          10</td><td style=\"text-align: right;\">    10</td><td style=\"text-align: right;\">         5.01506</td><td style=\"text-align: right;\">     0.942076</td></tr>\n",
       "<tr><td>lambda_5e0dd_00006</td><td>TERMINATED</td><td>127.0.0.1:49353</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">0.000610464</td><td style=\"text-align: right;\">          40</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         9.59968</td><td style=\"text-align: right;\">     0.965788</td></tr>\n",
       "<tr><td>lambda_5e0dd_00007</td><td>TERMINATED</td><td>127.0.0.1:49354</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">0.00112484 </td><td style=\"text-align: right;\">         100</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">        17.3383 </td><td style=\"text-align: right;\">     0.970567</td></tr>\n",
       "<tr><td>lambda_5e0dd_00008</td><td>TERMINATED</td><td>127.0.0.1:49386</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">7.63098e-05</td><td style=\"text-align: right;\">          40</td><td style=\"text-align: right;\">    40</td><td style=\"text-align: right;\">         5.65983</td><td style=\"text-align: right;\">     0.855997</td></tr>\n",
       "<tr><td>lambda_5e0dd_00009</td><td>TERMINATED</td><td>127.0.0.1:49400</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">0.000271322</td><td style=\"text-align: right;\">         100</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">        12.3451 </td><td style=\"text-align: right;\">     0.96828 </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m Warning: The actor ImplicitFunc is very large (17 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store.\n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m Epoch 1/1\n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m Average Loss (Label): 0.6043\n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m Average Loss (Type): 1.5488\n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m Total Loss: 2.1532\n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m Training complete.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name        </th><th style=\"text-align: right;\">  combined_f1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>lambda_5e0dd_00000</td><td style=\"text-align: right;\">     0.968847</td></tr>\n",
       "<tr><td>lambda_5e0dd_00001</td><td style=\"text-align: right;\">     0.963778</td></tr>\n",
       "<tr><td>lambda_5e0dd_00002</td><td style=\"text-align: right;\">     0.966345</td></tr>\n",
       "<tr><td>lambda_5e0dd_00003</td><td style=\"text-align: right;\">     0.609781</td></tr>\n",
       "<tr><td>lambda_5e0dd_00004</td><td style=\"text-align: right;\">     0.966367</td></tr>\n",
       "<tr><td>lambda_5e0dd_00005</td><td style=\"text-align: right;\">     0.942076</td></tr>\n",
       "<tr><td>lambda_5e0dd_00006</td><td style=\"text-align: right;\">     0.965788</td></tr>\n",
       "<tr><td>lambda_5e0dd_00007</td><td style=\"text-align: right;\">     0.970567</td></tr>\n",
       "<tr><td>lambda_5e0dd_00008</td><td style=\"text-align: right;\">     0.855997</td></tr>\n",
       "<tr><td>lambda_5e0dd_00009</td><td style=\"text-align: right;\">     0.96828 </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49352)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49358)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49357)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49352)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49358)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49352)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49358)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49352)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49358)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49357)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49352)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49358)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49352)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49358)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49357)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49352)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49358)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49352)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49358)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49357)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49352)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49358)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49357)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49352)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49358)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49352)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49358)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49357)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49352)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49358)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49357)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49352)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49358)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49358)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49352)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49357)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49352)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49358)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49352)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49358)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49357)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49352)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49358)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49357)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49352)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49358)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49358)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49352)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49352)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49358)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49358)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49352)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49352)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49358)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49352)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49358)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49358)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49352)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49358)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49352)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m Epoch 1/1\u001b[32m [repeated 188x across cluster] (Ray deduplicates logs by default. Set RAY_DEDUP_LOGS=0 to disable log deduplication, or see https://docs.ray.io/en/master/ray-observability/user-guides/configure-logging.html#log-deduplication for more options.)\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m Average Loss (Label): 0.5976\u001b[32m [repeated 188x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m Average Loss (Type): 1.4459\u001b[32m [repeated 188x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m Total Loss: 2.0435\u001b[32m [repeated 188x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m Training complete.\u001b[32m [repeated 188x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49352)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49358)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49358)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49352)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49358)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49352)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49358)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49352)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49352)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49358)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49358)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49358)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49358)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49358)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49358)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49358)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49358)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49358)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49358)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49358)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[36m(<lambda> pid=49353)\u001b[0m *** SIGSEGV received at time=1741608947 ***\n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m PC: @        0x112bbb8c0  (unknown)  ray::rpc::GcsRpcClient::AddTaskEventData()\n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m     @        0x113587e54  (unknown)  absl::lts_20230802::AbslFailureSignalHandler()\n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m     @        0x192966de4  (unknown)  _sigtramp\n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m     @        0x112bbb784  (unknown)  ray::gcs::TaskInfoAccessor::AsyncAddTaskEventData()\n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m     @        0x112bbb784  (unknown)  ray::gcs::TaskInfoAccessor::AsyncAddTaskEventData()\n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m     @        0x112af5894  (unknown)  ray::core::worker::TaskEventBufferImpl::FlushEvents()\n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m     @        0x1129be7cc  (unknown)  ray::core::CoreWorker::Disconnect()\n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m     @        0x1129bfd08  (unknown)  ray::core::CoreWorker::ForceExit()\n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m     @        0x1129e1070  (unknown)  ray::core::CoreWorker::HandleKillActor()\n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m     @        0x112a11d98  (unknown)  ray::rpc::ServerCallImpl<>::HandleRequestImpl()\n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m     @        0x112e6d544  (unknown)  EventTracker::RecordExecution()\n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m     @        0x112e43bc4  (unknown)  std::__1::__function::__func<>::operator()()\n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m     @        0x112e432c8  (unknown)  boost::asio::detail::completion_handler<>::do_complete()\n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m     @        0x113596820  (unknown)  boost::asio::detail::scheduler::do_run_one()\n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m     @        0x11358b398  (unknown)  boost::asio::detail::scheduler::run()\n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m     @        0x11358b280  (unknown)  boost::asio::io_context::run()\n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m     @        0x1129bfde8  (unknown)  ray::core::CoreWorker::RunIOService()\n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m     @        0x112f73908  (unknown)  boost::(anonymous namespace)::thread_proxy()\n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m     @        0x1929302e4  (unknown)  _pthread_start\n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m     @        0x19292b0fc  (unknown)  thread_start\n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m [2025-03-10 20:15:47,659 E 49353 399421] logging.cc:484: *** SIGSEGV received at time=1741608947 ***\n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m [2025-03-10 20:15:47,659 E 49353 399421] logging.cc:484: PC: @        0x112bbb8c0  (unknown)  ray::rpc::GcsRpcClient::AddTaskEventData()\n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m [2025-03-10 20:15:47,659 E 49353 399421] logging.cc:484:     @        0x113587f74  (unknown)  absl::lts_20230802::AbslFailureSignalHandler()\n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m [2025-03-10 20:15:47,659 E 49353 399421] logging.cc:484:     @        0x192966de4  (unknown)  _sigtramp\n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m [2025-03-10 20:15:47,659 E 49353 399421] logging.cc:484:     @        0x112bbb784  (unknown)  ray::gcs::TaskInfoAccessor::AsyncAddTaskEventData()\n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m [2025-03-10 20:15:47,659 E 49353 399421] logging.cc:484:     @        0x112bbb784  (unknown)  ray::gcs::TaskInfoAccessor::AsyncAddTaskEventData()\n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m [2025-03-10 20:15:47,659 E 49353 399421] logging.cc:484:     @        0x112af5894  (unknown)  ray::core::worker::TaskEventBufferImpl::FlushEvents()\n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m [2025-03-10 20:15:47,659 E 49353 399421] logging.cc:484:     @        0x1129be7cc  (unknown)  ray::core::CoreWorker::Disconnect()\n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m [2025-03-10 20:15:47,659 E 49353 399421] logging.cc:484:     @        0x1129bfd08  (unknown)  ray::core::CoreWorker::ForceExit()\n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m [2025-03-10 20:15:47,659 E 49353 399421] logging.cc:484:     @        0x1129e1070  (unknown)  ray::core::CoreWorker::HandleKillActor()\n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m [2025-03-10 20:15:47,660 E 49353 399421] logging.cc:484:     @        0x112a11d98  (unknown)  ray::rpc::ServerCallImpl<>::HandleRequestImpl()\n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m [2025-03-10 20:15:47,660 E 49353 399421] logging.cc:484:     @        0x112e6d544  (unknown)  EventTracker::RecordExecution()\n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m [2025-03-10 20:15:47,660 E 49353 399421] logging.cc:484:     @        0x112e43bc4  (unknown)  std::__1::__function::__func<>::operator()()\n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m [2025-03-10 20:15:47,660 E 49353 399421] logging.cc:484:     @        0x112e432c8  (unknown)  boost::asio::detail::completion_handler<>::do_complete()\n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m [2025-03-10 20:15:47,660 E 49353 399421] logging.cc:484:     @        0x113596820  (unknown)  boost::asio::detail::scheduler::do_run_one()\n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m [2025-03-10 20:15:47,661 E 49353 399421] logging.cc:484:     @        0x11358b398  (unknown)  boost::asio::detail::scheduler::run()\n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m [2025-03-10 20:15:47,661 E 49353 399421] logging.cc:484:     @        0x11358b280  (unknown)  boost::asio::io_context::run()\n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m [2025-03-10 20:15:47,661 E 49353 399421] logging.cc:484:     @        0x1129bfde8  (unknown)  ray::core::CoreWorker::RunIOService()\n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m [2025-03-10 20:15:47,661 E 49353 399421] logging.cc:484:     @        0x112f73908  (unknown)  boost::(anonymous namespace)::thread_proxy()\n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m [2025-03-10 20:15:47,661 E 49353 399421] logging.cc:484:     @        0x1929302e4  (unknown)  _pthread_start\n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m [2025-03-10 20:15:47,661 E 49353 399421] logging.cc:484:     @        0x19292b0fc  (unknown)  thread_start\n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m Fatal Python error: Segmentation fault\n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49353)\u001b[0m Extension modules: msgpack._cmsgpack, google._upb._message, psutil._psutil_osx, psutil._psutil_posix, setproctitle, yaml._yaml, charset_normalizer.md, requests.packages.charset_normalizer.md, requests.packages.chardet.md, ray._raylet, numpy.core._multiarray_umath, numpy.core._multiarray_tests, numpy.linalg._umath_linalg, numpy.fft._pocketfft_internal, numpy.random._common, numpy.random.bit_generator, numpy.random._bounded_integers, numpy.random._mt19937, numpy.random.mtrand, numpy.random._philox, numpy.random._pcg64, numpy.random._sfc64, numpy.random._generator, pyarrow.lib, pandas._libs.tslibs.ccalendar, pandas._libs.tslibs.np_datetime, pandas._libs.tslibs.dtypes, pandas._libs.tslibs.base, pandas._libs.tslibs.nattype, pandas._libs.tslibs.timezones, pandas._libs.tslibs.fields, pandas._libs.tslibs.timedeltas, pandas._libs.tslibs.tzconversion, pandas._libs.tslibs.timestamps, pandas._libs.properties, pandas._libs.tslibs.offsets, pandas._libs.tslibs.strptime, pandas._libs.tslibs.parsing, pandas._libs.tslibs.conversion, pandas._libs.tslibs.period, pandas._libs.tslibs.vectorized, pandas._libs.ops_dispatch, pandas._libs.missing, pandas._libs.hashtable, pandas._libs.algos, pandas._libs.interval, pandas._libs.lib, pyarrow._compute, pandas._libs.ops, pandas._libs.hashing, pandas._libs.arrays, pandas._libs.tslib, pandas._libs.sparse, pandas._libs.internals, pandas._libs.indexing, pandas._libs.index, pandas._libs.writers, pandas._libs.join, pandas._libs.window.aggregations, pandas._libs.window.indexers, pandas._libs.reshape, pandas._libs.groupby, pandas._libs.json, pandas._libs.parsers, pandas._libs.testing, pyarrow._fs, pyarrow._azurefs, pyarrow._hdfs, pyarrow._gcsfs, pyarrow._s3fs, pyarrow._parquet, scipy._lib._ccallback_c, scipy.sparse._sparsetools, _csparsetools, scipy.sparse._csparsetools, scipy.linalg._fblas, scipy.linalg._flapack, scipy.linalg.cython_lapack, scipy.linalg._cythonized_array_utils, scipy.linalg._solve_toeplitz, scipy.linalg._decomp_lu_cython, scipy.linalg._matfuncs_sqrtm_triu, scipy.linalg.cython_blas, scipy.linalg._matfuncs_expm, scipy.linalg._decomp_update, scipy.sparse.linalg._dsolve._superlu, scipy.sparse.linalg._eigen.arpack._arpack, scipy.sparse.linalg._propack._spropack, scipy.sparse.linalg._propack._dpropack, scipy.sparse.linalg._propack._cpropack, scipy.sparse.linalg._propack._zpropack, scipy.sparse.csgraph._tools, scipy.sparse.csgraph._shortest_path, scipy.sparse.csgraph._traversal, scipy.sparse.csgraph._min_spanning_tree, scipy.sparse.csgraph._flow, scipy.sparse.csgraph._matching, scipy.sparse.csgraph._reordering, torch._C, torch._C._dynamo.autograd_compiler, torch._C._dynamo.eval_frame, torch._C._dynamo.guards, torch._C._dynamo.utils, torch._C._fft, torch._C._linalg, torch._C._nested, torch._C._nn, torch._C._sparse, torch._C._special, PIL._imaging, kiwisolver._cext, sklearn.__check_build._check_build, scipy.special._ufuncs_cxx, scipy.special._cdflib, scipy.special._ufuncs, scipy.special._specfun, scipy.special._comb, scipy.special._ellip_harm_2, scipy.spatial._ckdtree, scipy._lib.messagestream, scipy.spatial._qhull, scipy.spatial._voronoi, scipy.spatial._distance_wrap, scipy.spatial._hausdorff, scipy.spatial.transform._rotation, scipy.ndimage._nd_image, _ni_label, scipy.ndimage._ni_label, scipy.optimize._minpack2, scipy.optimize._group_columns, scipy.optimize._trlib._trlib, scipy.optimize._lbfgsb, _moduleTNC, scipy.optimize._moduleTNC, scipy.optimize._cobyla, scipy.optimize._slsqp, scipy.optimize._minpack, scipy.optimize._lsq.givens_elimination, scipy.optimize._zeros, scipy.optimize._highs.cython.src._highs_wrapper, scipy.optimize._highs._highs_wrapper, scipy.optimize._highs.cython.src._highs_constants, scipy.optimize._highs._highs_constants, scipy.linalg._interpolative, scipy.optimize._bglu_dense, scipy.optimize._lsap, scipy.optimize._direct, scipy.integrate._odepack, scipy.integrate._quadpack, scipy.integrate._vode, scipy.integrate._dop, scipy.integrate._lsoda, scipy.special.cython_special, scipy.stats._stats, scipy.stats.beta_ufunc, scipy.stats._boost.beta_ufunc, scipy.stats.binom_ufunc, scipy.stats._boost.binom_ufunc, scipy.stats.nbinom_ufunc, scipy.stats._boost.nbinom_ufunc, scipy.stats.hypergeom_ufunc, scipy.stats._boost.hypergeom_ufunc, scipy.stats.ncf_ufunc, scipy.stats._boost.ncf_ufunc, scipy.stats.ncx2_ufunc, scipy.stats._boost.ncx2_ufunc, scipy.stats.nct_ufunc, scipy.stats._boost.nct_ufunc, scipy.stats.skewnorm_ufunc, scipy.stats._boost.skewnorm_ufunc, scipy.stats.invgauss_ufunc, scipy.stats._boost.invgauss_ufunc, scipy.interpolate._fitpack, scipy.interpolate.dfitpack, scipy.interpolate._bspl, scipy.interpolate._ppoly, scipy.interpolate.interpnd, scipy.interpolate._rbfinterp_pythran, scipy.interpolate._rgi_cython, scipy.stats._biasedurn, scipy.stats._levy_stable.levyst, scipy.stats._stats_pythran, scipy._lib._uarray._uarray, scipy.stats._ansari_swilk_statistics, scipy.stats._sobol, scipy.stats._qmc_cy, scipy.stats._mvn, scipy.stats._rcont.rcont, scipy.stats._unuran.unuran_wrapper, sklearn.utils._isfinite, sklearn.utils.sparsefuncs_fast, sklearn.utils.murmurhash, sklearn.utils._openmp_helpers, sklearn.metrics.cluster._expected_mutual_info_fast, sklearn.preprocessing._csr_polynomial_expansion, sklearn.preprocessing._target_encoder_fast, sklearn.metrics._dist_metrics, sklearn.metrics._pairwise_distances_reduction._datasets_pair, sklearn.utils._cython_blas, sklearn.metrics._pairwise_distances_reduction._base, sklearn.metrics._pairwise_distances_reduction._middle_term_computer, sklearn.utils._heap, sklearn.utils._sorting, sklearn.metrics._pairwise_distances_reduction._argkmin, sklearn.metrics._pairwise_distances_reduction._argkmin_classmode, sklearn.utils._vector_sentinel, sklearn.metrics._pairwise_distances_reduction._radius_neighbors, sklearn.metrics._pairwise_distances_reduction._radius_neighbors_classmode, sklearn.metrics._pairwise_fast, scipy.cluster._vq, scipy.cluster._hierarchy, scipy.cluster._optimal_leaf_ordering, pyarrow._json (total: 213)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49386)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49386)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49386)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49386)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49356)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49386)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49386)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49386)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49386)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49386)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49386)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m Epoch 1/1\u001b[32m [repeated 156x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m Average Loss (Label): 0.0037\u001b[32m [repeated 156x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m Average Loss (Type): 0.0056\u001b[32m [repeated 156x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m Total Loss: 0.0093\u001b[32m [repeated 156x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m Training complete.\u001b[32m [repeated 156x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49386)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49386)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49386)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49386)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49386)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49386)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49386)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49355)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49386)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49386)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49386)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49386)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49386)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49386)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49386)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49386)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49386)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49386)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49386)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49386)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49386)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49386)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49386)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49386)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49386)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49386)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49386)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49386)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49386)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49386)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49386)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m Epoch 1/1\u001b[32m [repeated 138x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m Average Loss (Label): 0.0015\u001b[32m [repeated 138x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m Average Loss (Type): 0.0021\u001b[32m [repeated 138x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m Total Loss: 0.0036\u001b[32m [repeated 138x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m Training complete.\u001b[32m [repeated 138x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49354)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m Epoch 1/1\u001b[32m [repeated 77x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m Average Loss (Label): 0.0172\u001b[32m [repeated 77x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m Average Loss (Type): 0.0330\u001b[32m [repeated 77x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m Total Loss: 0.0503\u001b[32m [repeated 77x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m Training complete.\u001b[32m [repeated 77x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49400)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 20:16:02,802\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/Users/choonkeatling/ray_results/lambda_2025-03-10_20-15-34' in 0.0046s.\n",
      "2025-03-10 20:16:02,805\tINFO tune.py:1041 -- Total run time: 28.73 seconds (28.69 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best hyperparameters for DistilBERT:\n",
      "{'lr': 0.001124840994193108, 'batch_size': 32, 'num_epochs': 100}\n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m \n",
      "Epoch 1/100\n",
      "Average Loss (Label): 0.6298\n",
      "Average Loss (Type): 1.5635\n",
      "Total Loss: 2.1933\n",
      "\n",
      "Epoch 11/100\n",
      "Average Loss (Label): 0.0813\n",
      "Average Loss (Type): 0.2384\n",
      "Total Loss: 0.3197\n",
      "\n",
      "Epoch 21/100\n",
      "Average Loss (Label): 0.0302\n",
      "Average Loss (Type): 0.0760\n",
      "Total Loss: 0.1062\n",
      "\n",
      "Epoch 31/100\n",
      "Average Loss (Label): 0.0219\n",
      "Average Loss (Type): 0.0352\n",
      "Total Loss: 0.0571\n",
      "\n",
      "Epoch 41/100\n",
      "Average Loss (Label): 0.0101\n",
      "Average Loss (Type): 0.0173\n",
      "Total Loss: 0.0274\n",
      "\n",
      "Epoch 51/100\n",
      "Average Loss (Label): 0.0078\n",
      "Average Loss (Type): 0.0108\n",
      "Total Loss: 0.0186\n",
      "\n",
      "Epoch 61/100\n",
      "Average Loss (Label): 0.0047\n",
      "Average Loss (Type): 0.0064\n",
      "Total Loss: 0.0111\n",
      "\n",
      "Epoch 71/100\n",
      "Average Loss (Label): 0.0031\n",
      "Average Loss (Type): 0.0046\n",
      "Total Loss: 0.0077\n",
      "\n",
      "Epoch 81/100\n",
      "Average Loss (Label): 0.0021\n",
      "Average Loss (Type): 0.0025\n",
      "Total Loss: 0.0046\n",
      "\n",
      "Epoch 91/100\n",
      "Average Loss (Label): 0.0015\n",
      "Average Loss (Type): 0.0022\n",
      "Total Loss: 0.0037\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 20:16:11,363\tINFO tune.py:616 -- [output] This uses the legacy output and progress reporter, as Jupyter notebooks are not supported by the new engine, yet. For more information, please see https://github.com/ray-project/ray/issues/36949\n",
      "2025-03-10 20:16:11,383\tWARNING callback.py:136 -- The TensorboardX logger cannot be instantiated because either TensorboardX or one of it's dependencies is not installed. Please make sure you have the latest version of TensorboardX installed: `pip install -U tensorboardx`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete.\n",
      "\n",
      "Evaluation results for DistilBERT: ((0.9683333333333334, 0.9838187702265372, 0.9559748427672956, 0.9696969696969697, array([[277,   5],\n",
      "       [ 14, 304]])), (0.955, 0.9555052857868447, 0.955, 0.9548564125362895, array([[ 35,   1,   0,   1,   0,   0,   0,   0,   0],\n",
      "       [  2,  18,   0,   0,   1,   0,   0,   0,   0],\n",
      "       [  0,   0,  47,   2,   0,   0,   0,   0,   0],\n",
      "       [  0,   0,   0, 279,   1,   0,   2,   0,   0],\n",
      "       [  0,   0,   0,   1,  28,   0,   0,   1,   0],\n",
      "       [  0,   0,   0,   2,   0,  22,   0,   0,   0],\n",
      "       [  1,   0,   0,   4,   0,   1,  86,   2,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   2,  15,   0],\n",
      "       [  0,   0,   0,   2,   0,   0,   1,   0,  43]])))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"tuneStatus\">\n",
       "  <div style=\"display: flex;flex-direction: row\">\n",
       "    <div style=\"display: flex;flex-direction: column;\">\n",
       "      <h3>Tune Status</h3>\n",
       "      <table>\n",
       "<tbody>\n",
       "<tr><td>Current time:</td><td>2025-03-10 20:16:47</td></tr>\n",
       "<tr><td>Running for: </td><td>00:00:35.87        </td></tr>\n",
       "<tr><td>Memory:      </td><td>10.5/16.0 GiB      </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "    </div>\n",
       "    <div class=\"vDivider\"></div>\n",
       "    <div class=\"systemInfo\">\n",
       "      <h3>System Info</h3>\n",
       "      Using FIFO scheduling algorithm.<br>Logical resource usage: 1.0/8 CPUs, 0/0 GPUs\n",
       "    </div>\n",
       "    \n",
       "  </div>\n",
       "  <div class=\"hDivider\"></div>\n",
       "  <div class=\"trialStatus\">\n",
       "    <h3>Trial Status</h3>\n",
       "    <table>\n",
       "<thead>\n",
       "<tr><th>Trial name        </th><th>status    </th><th>loc            </th><th style=\"text-align: right;\">  batch_size</th><th style=\"text-align: right;\">         lr</th><th style=\"text-align: right;\">  num_epochs</th><th style=\"text-align: right;\">  iter</th><th style=\"text-align: right;\">  total time (s)</th><th style=\"text-align: right;\">  combined_f1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>lambda_74464_00000</td><td>TERMINATED</td><td>127.0.0.1:49465</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">4.08643e-05</td><td style=\"text-align: right;\">         100</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">        12.3619 </td><td style=\"text-align: right;\">     0.783776</td></tr>\n",
       "<tr><td>lambda_74464_00001</td><td>TERMINATED</td><td>127.0.0.1:49464</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">7.38242e-05</td><td style=\"text-align: right;\">          50</td><td style=\"text-align: right;\">    50</td><td style=\"text-align: right;\">        16.652  </td><td style=\"text-align: right;\">     0.918784</td></tr>\n",
       "<tr><td>lambda_74464_00002</td><td>TERMINATED</td><td>127.0.0.1:49466</td><td style=\"text-align: right;\">          64</td><td style=\"text-align: right;\">0.000527343</td><td style=\"text-align: right;\">          60</td><td style=\"text-align: right;\">    60</td><td style=\"text-align: right;\">         7.96054</td><td style=\"text-align: right;\">     0.966951</td></tr>\n",
       "<tr><td>lambda_74464_00003</td><td>TERMINATED</td><td>127.0.0.1:49469</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">1.1372e-05 </td><td style=\"text-align: right;\">          60</td><td style=\"text-align: right;\">    60</td><td style=\"text-align: right;\">        12.757  </td><td style=\"text-align: right;\">     0.60866 </td></tr>\n",
       "<tr><td>lambda_74464_00004</td><td>TERMINATED</td><td>127.0.0.1:49467</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">0.000102706</td><td style=\"text-align: right;\">          30</td><td style=\"text-align: right;\">    30</td><td style=\"text-align: right;\">         7.21534</td><td style=\"text-align: right;\">     0.821306</td></tr>\n",
       "<tr><td>lambda_74464_00005</td><td>TERMINATED</td><td>127.0.0.1:49470</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">0.000129673</td><td style=\"text-align: right;\">          60</td><td style=\"text-align: right;\">    60</td><td style=\"text-align: right;\">        12.1114 </td><td style=\"text-align: right;\">     0.943172</td></tr>\n",
       "<tr><td>lambda_74464_00006</td><td>TERMINATED</td><td>127.0.0.1:49468</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">0.00889349 </td><td style=\"text-align: right;\">          70</td><td style=\"text-align: right;\">    70</td><td style=\"text-align: right;\">        14.0936 </td><td style=\"text-align: right;\">     0.972013</td></tr>\n",
       "<tr><td>lambda_74464_00007</td><td>TERMINATED</td><td>127.0.0.1:49471</td><td style=\"text-align: right;\">          32</td><td style=\"text-align: right;\">3.15883e-05</td><td style=\"text-align: right;\">         100</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">        16.9876 </td><td style=\"text-align: right;\">     0.827388</td></tr>\n",
       "<tr><td>lambda_74464_00008</td><td>TERMINATED</td><td>127.0.0.1:49500</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">0.00266899 </td><td style=\"text-align: right;\">         100</td><td style=\"text-align: right;\">   100</td><td style=\"text-align: right;\">        19.6698 </td><td style=\"text-align: right;\">     0.970511</td></tr>\n",
       "<tr><td>lambda_74464_00009</td><td>TERMINATED</td><td>127.0.0.1:49506</td><td style=\"text-align: right;\">          16</td><td style=\"text-align: right;\">0.000425288</td><td style=\"text-align: right;\">          70</td><td style=\"text-align: right;\">    70</td><td style=\"text-align: right;\">        13.9727 </td><td style=\"text-align: right;\">     0.968575</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "  </div>\n",
       "</div>\n",
       "<style>\n",
       ".tuneStatus {\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".tuneStatus .systemInfo {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       ".tuneStatus .trialStatus {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       ".tuneStatus h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".tuneStatus .hDivider {\n",
       "  border-bottom-width: var(--jp-border-width);\n",
       "  border-bottom-color: var(--jp-border-color0);\n",
       "  border-bottom-style: solid;\n",
       "}\n",
       ".tuneStatus .vDivider {\n",
       "  border-left-width: var(--jp-border-width);\n",
       "  border-left-color: var(--jp-border-color0);\n",
       "  border-left-style: solid;\n",
       "  margin: 0.5em 1em 0.5em 1em;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33m(raylet)\u001b[0m Warning: The actor ImplicitFunc is very large (17 MiB). Check that its definition is not implicitly capturing a large array or other object in scope. Tip: use ray.put() to put large objects in the Ray object store.\n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m Epoch 1/1\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m Average Loss (Label): 0.0002\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m Average Loss (Type): 0.0013\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m Total Loss: 0.0016\u001b[32m [repeated 30x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49351)\u001b[0m Training complete.\u001b[32m [repeated 30x across cluster]\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div class=\"trialProgress\">\n",
       "  <h3>Trial Progress</h3>\n",
       "  <table>\n",
       "<thead>\n",
       "<tr><th>Trial name        </th><th style=\"text-align: right;\">  combined_f1</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr><td>lambda_74464_00000</td><td style=\"text-align: right;\">     0.783776</td></tr>\n",
       "<tr><td>lambda_74464_00001</td><td style=\"text-align: right;\">     0.918784</td></tr>\n",
       "<tr><td>lambda_74464_00002</td><td style=\"text-align: right;\">     0.966951</td></tr>\n",
       "<tr><td>lambda_74464_00003</td><td style=\"text-align: right;\">     0.60866 </td></tr>\n",
       "<tr><td>lambda_74464_00004</td><td style=\"text-align: right;\">     0.821306</td></tr>\n",
       "<tr><td>lambda_74464_00005</td><td style=\"text-align: right;\">     0.943172</td></tr>\n",
       "<tr><td>lambda_74464_00006</td><td style=\"text-align: right;\">     0.972013</td></tr>\n",
       "<tr><td>lambda_74464_00007</td><td style=\"text-align: right;\">     0.827388</td></tr>\n",
       "<tr><td>lambda_74464_00008</td><td style=\"text-align: right;\">     0.970511</td></tr>\n",
       "<tr><td>lambda_74464_00009</td><td style=\"text-align: right;\">     0.968575</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>\n",
       "<style>\n",
       ".trialProgress {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  color: var(--jp-ui-font-color1);\n",
       "}\n",
       ".trialProgress h3 {\n",
       "  font-weight: bold;\n",
       "}\n",
       ".trialProgress td {\n",
       "  white-space: nowrap;\n",
       "}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m Epoch 1/1\n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m Average Loss (Label): 0.6940\n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m Average Loss (Type): 2.2073\n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m Total Loss: 2.9013\n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m Training complete.\n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m Epoch 1/1\n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m Average Loss (Label): 0.3144\n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m Average Loss (Type): 1.0088\n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m Total Loss: 1.3232\n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m Training complete.\n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49467)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49467)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49467)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49467)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49467)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49467)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49467)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49467)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49467)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49467)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49467)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49467)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49467)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49467)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49467)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49467)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49467)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49467)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49467)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49467)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49467)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49467)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49467)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49467)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49467)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49467)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49467)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49467)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m Epoch 1/1\u001b[32m [repeated 238x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m Average Loss (Label): 0.1496\u001b[32m [repeated 238x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m Average Loss (Type): 0.5440\u001b[32m [repeated 238x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m Total Loss: 0.6936\u001b[32m [repeated 238x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m Training complete.\u001b[32m [repeated 238x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49467)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49467)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49467)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49466)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m Epoch 1/1\u001b[32m [repeated 194x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m Average Loss (Label): 0.0701\u001b[32m [repeated 194x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m Average Loss (Type): 0.2196\u001b[32m [repeated 194x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m Total Loss: 0.2897\u001b[32m [repeated 194x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m Training complete.\u001b[32m [repeated 194x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49470)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49465)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49469)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49468)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49464)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m Epoch 1/1\u001b[32m [repeated 125x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m Average Loss (Label): 0.1848\u001b[32m [repeated 125x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m Average Loss (Type): 0.6576\u001b[32m [repeated 125x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m Total Loss: 0.8423\u001b[32m [repeated 125x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m Training complete.\u001b[32m [repeated 125x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49471)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m Epoch 1/1\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m Average Loss (Label): 0.0002\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m Average Loss (Type): 0.0004\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m Total Loss: 0.0006\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m Training complete.\u001b[32m [repeated 59x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m Epoch 1/1\u001b[32m [repeated 54x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m Average Loss (Label): 0.0001\u001b[32m [repeated 54x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m Average Loss (Type): 0.0001\u001b[32m [repeated 54x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m Total Loss: 0.0002\u001b[32m [repeated 54x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m Training complete.\u001b[32m [repeated 54x across cluster]\u001b[0m\n",
      "\u001b[36m(<lambda> pid=49506)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-03-10 20:16:47,253\tINFO tune.py:1009 -- Wrote the latest version of all result files and experiment state to '/Users/choonkeatling/ray_results/lambda_2025-03-10_20-16-11' in 0.0047s.\n",
      "2025-03-10 20:16:47,256\tINFO tune.py:1041 -- Total run time: 35.89 seconds (35.86 seconds for the tuning loop).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best hyperparameters for SBERT:\n",
      "{'lr': 0.00889349277524112, 'batch_size': 32, 'num_epochs': 70}\n",
      "\u001b[36m(<lambda> pid=49500)\u001b[0m \n",
      "Epoch 1/70\n",
      "Average Loss (Label): 0.3390\n",
      "Average Loss (Type): 1.0752\n",
      "Total Loss: 1.4142\n",
      "\n",
      "Epoch 11/70\n",
      "Average Loss (Label): 0.0011\n",
      "Average Loss (Type): 0.0027\n",
      "Total Loss: 0.0038\n",
      "\n",
      "Epoch 21/70\n",
      "Average Loss (Label): 0.0003\n",
      "Average Loss (Type): 0.0009\n",
      "Total Loss: 0.0012\n",
      "\n",
      "Epoch 31/70\n",
      "Average Loss (Label): 0.0002\n",
      "Average Loss (Type): 0.0004\n",
      "Total Loss: 0.0005\n",
      "\n",
      "Epoch 41/70\n",
      "Average Loss (Label): 0.0001\n",
      "Average Loss (Type): 0.0002\n",
      "Total Loss: 0.0003\n",
      "\n",
      "Epoch 51/70\n",
      "Average Loss (Label): 0.0001\n",
      "Average Loss (Type): 0.0002\n",
      "Total Loss: 0.0002\n",
      "\n",
      "Epoch 61/70\n",
      "Average Loss (Label): 0.0000\n",
      "Average Loss (Type): 0.0001\n",
      "Total Loss: 0.0001\n",
      "\n",
      "Training complete.\n",
      "\n",
      "Evaluation results for SBERT: ((0.985, 0.9904761904761905, 0.9811320754716981, 0.985781990521327, array([[279,   3],\n",
      "       [  6, 312]])), (0.9766666666666667, 0.9773654440980499, 0.9766666666666667, 0.9763848540364887, array([[ 35,   0,   0,   1,   0,   0,   1,   0,   0],\n",
      "       [  0,  18,   0,   2,   0,   0,   1,   0,   0],\n",
      "       [  0,   0,  49,   0,   0,   0,   0,   0,   0],\n",
      "       [  0,   0,   0, 281,   0,   0,   1,   0,   0],\n",
      "       [  0,   1,   0,   1,  28,   0,   0,   0,   0],\n",
      "       [  0,   0,   0,   1,   0,  23,   0,   0,   0],\n",
      "       [  0,   0,   0,   1,   0,   0,  93,   0,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   3,  14,   0],\n",
      "       [  0,   0,   0,   0,   0,   0,   1,   0,  45]])))\n"
     ]
    }
   ],
   "source": [
    "from ray import tune\n",
    "\n",
    "\n",
    "def train_model(config, embedding):\n",
    "    # Assume you're working with the DistilBERT embeddings\n",
    "    data = embedding_data[embedding]\n",
    "    # Convert to dense if needed\n",
    "    X_train = (\n",
    "        data[\"X_train\"].toarray()\n",
    "        if scipy.sparse.issparse(data[\"X_train\"])\n",
    "        else data[\"X_train\"]\n",
    "    )\n",
    "    X_val = (\n",
    "        data[\"X_val\"].toarray()\n",
    "        if scipy.sparse.issparse(data[\"X_val\"])\n",
    "        else data[\"X_val\"]\n",
    "    )\n",
    "\n",
    "    # Instantiate the model with hyperparameters from config.\n",
    "    model = MutltiTaskModel(\n",
    "        X_train,\n",
    "        data[\"y1_train\"],\n",
    "        data[\"y2_train\"],\n",
    "        num_types=len(le.classes_),\n",
    "        batch_size=config[\"batch_size\"],\n",
    "        lr=config[\"lr\"],\n",
    "    )\n",
    "\n",
    "    num_epochs = config[\"num_epochs\"]\n",
    "\n",
    "    # Training loop\n",
    "    for epoch in range(num_epochs):\n",
    "        # Train for one epoch at a time\n",
    "        model.train(num_epochs=1)\n",
    "\n",
    "        # Evaluate on validation data after each epoch\n",
    "        (_, _, _, f1_label, _), (_, _, _, f1_type, _) = model.evaluate(\n",
    "            X_val, data[\"y1_val\"], data[\"y2_val\"]\n",
    "        )\n",
    "\n",
    "        # Create a combined metric. Adjust weights if necessary.\n",
    "        combined_f1 = (f1_label + f1_type) / 2\n",
    "\n",
    "        # Report the combined F1 score\n",
    "        tune.report({\"combined_f1\": combined_f1})\n",
    "\n",
    "\n",
    "# Define the hyperparameter search space.\n",
    "config = {\n",
    "    \"lr\": tune.loguniform(1e-5, 1e-2),\n",
    "    \"batch_size\": tune.choice([16, 32, 64]),\n",
    "    \"num_epochs\": tune.choice([10, 20, 30, 40, 50, 60, 70, 80, 90, 100]),\n",
    "}\n",
    "\n",
    "# Run the tuning experiment for each embedding\n",
    "\n",
    "for embedding in embedding_data.keys():\n",
    "    analysis = tune.run(\n",
    "        lambda config: train_model(config, embedding),\n",
    "        config=config,\n",
    "        metric=\"combined_f1\",\n",
    "        mode=\"max\",\n",
    "        num_samples=10,  # Increase this number for a broader search\n",
    "    )\n",
    "\n",
    "    print(f\"\\nBest hyperparameters for {embedding}:\")\n",
    "    print(analysis.get_best_config(metric=\"combined_f1\", mode=\"max\"))\n",
    "\n",
    "    # Store the best model for each embedding\n",
    "    model =  MutltiTaskModel(\n",
    "        embedding_data[embedding][\"X_train\"],\n",
    "        embedding_data[embedding][\"y1_train\"],\n",
    "        embedding_data[embedding][\"y2_train\"],\n",
    "        num_types=len(le.classes_),\n",
    "        batch_size=analysis.get_best_config(metric=\"combined_f1\", mode=\"max\")[\"batch_size\"],\n",
    "        lr=analysis.get_best_config(metric=\"combined_f1\", mode=\"max\")[\"lr\"],\n",
    "    )\n",
    "\n",
    "    model.train(\n",
    "        num_epochs=analysis.get_best_config(metric=\"combined_f1\", mode=\"max\")[\"num_epochs\"]\n",
    "    )\n",
    "\n",
    "    mtl_result = model.evaluate(\n",
    "        embedding_data[embedding][\"X_test\"],\n",
    "        embedding_data[embedding][\"y1_test\"],\n",
    "        embedding_data[embedding][\"y2_test\"],\n",
    "    )\n",
    "\n",
    "    print(f\"\\nEvaluation results for {embedding}: {mtl_result}\")\n",
    "\n",
    "    # Create new row DataFrame\n",
    "    new_row = pd.DataFrame(\n",
    "        [\n",
    "            {\n",
    "                \"Algorithm\": \"Multi-Task Learning\",\n",
    "                \"Embedding\": embedding,\n",
    "                \"Type\": \"Test Set\",\n",
    "                \"y1_Accuracy\": mtl_result[0][0],\n",
    "                \"y1_Precision\": mtl_result[0][1],\n",
    "                \"y1_Recall\": mtl_result[0][2],\n",
    "                \"y1_F1_Score\": mtl_result[0][3],\n",
    "                \"y2_Accuracy\": mtl_result[1][0],\n",
    "                \"y2_Precision\": mtl_result[1][1],\n",
    "                \"y2_Recall\": mtl_result[1][2],\n",
    "                \"y2_F1_Score\": mtl_result[1][3],\n",
    "            }\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    # Concatenate new row to results DataFrame\n",
    "    result = pd.concat([result, new_row], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Algorithm",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Embedding",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "y1_Accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "y1_Precision",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "y1_Recall",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "y1_F1_Score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "y2_Accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "y2_Precision",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "y2_Recall",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "y2_F1_Score",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "d831531f-9606-4078-b3ca-ca3bccb41d21",
       "rows": [
        [
         "0",
         "SVM",
         "SBERT",
         "Test Set",
         "0.985",
         "0.9936102236421726",
         "0.9779874213836478",
         "0.9857369255150554",
         "0.98",
         "0.9803397258026016",
         "0.98",
         "0.9797386974272975"
        ],
        [
         "1",
         "Multi-Task Learning",
         "DistilBERT",
         "Test Set",
         "0.9683333333333334",
         "0.9838187702265372",
         "0.9559748427672956",
         "0.9696969696969697",
         "0.955",
         "0.9555052857868447",
         "0.955",
         "0.9548564125362895"
        ],
        [
         "2",
         "Multi-Task Learning",
         "SBERT",
         "Test Set",
         "0.985",
         "0.9904761904761905",
         "0.9811320754716981",
         "0.985781990521327",
         "0.9766666666666667",
         "0.9773654440980499",
         "0.9766666666666667",
         "0.9763848540364887"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Type</th>\n",
       "      <th>y1_Accuracy</th>\n",
       "      <th>y1_Precision</th>\n",
       "      <th>y1_Recall</th>\n",
       "      <th>y1_F1_Score</th>\n",
       "      <th>y2_Accuracy</th>\n",
       "      <th>y2_Precision</th>\n",
       "      <th>y2_Recall</th>\n",
       "      <th>y2_F1_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>SBERT</td>\n",
       "      <td>Test Set</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>0.993610</td>\n",
       "      <td>0.977987</td>\n",
       "      <td>0.985737</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.980340</td>\n",
       "      <td>0.980000</td>\n",
       "      <td>0.979739</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Multi-Task Learning</td>\n",
       "      <td>DistilBERT</td>\n",
       "      <td>Test Set</td>\n",
       "      <td>0.968333</td>\n",
       "      <td>0.983819</td>\n",
       "      <td>0.955975</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.955000</td>\n",
       "      <td>0.955505</td>\n",
       "      <td>0.955000</td>\n",
       "      <td>0.954856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Multi-Task Learning</td>\n",
       "      <td>SBERT</td>\n",
       "      <td>Test Set</td>\n",
       "      <td>0.985000</td>\n",
       "      <td>0.990476</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.985782</td>\n",
       "      <td>0.976667</td>\n",
       "      <td>0.977365</td>\n",
       "      <td>0.976667</td>\n",
       "      <td>0.976385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Algorithm   Embedding      Type  y1_Accuracy  y1_Precision  \\\n",
       "0                  SVM       SBERT  Test Set     0.985000      0.993610   \n",
       "1  Multi-Task Learning  DistilBERT  Test Set     0.968333      0.983819   \n",
       "2  Multi-Task Learning       SBERT  Test Set     0.985000      0.990476   \n",
       "\n",
       "   y1_Recall  y1_F1_Score  y2_Accuracy  y2_Precision  y2_Recall  y2_F1_Score  \n",
       "0   0.977987     0.985737     0.980000      0.980340   0.980000     0.979739  \n",
       "1   0.955975     0.969697     0.955000      0.955505   0.955000     0.954856  \n",
       "2   0.981132     0.985782     0.976667      0.977365   0.976667     0.976385  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Algorithm",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Embedding",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Type",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "y1_Accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "y1_Precision",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "y1_Recall",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "y1_F1_Score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "y2_Accuracy",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "y2_Precision",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "y2_Recall",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "y2_F1_Score",
         "rawType": "float64",
         "type": "float"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "862609a1-cc86-4e90-b63f-0a15212f0b51",
       "rows": [
        [
         "19",
         "SVM",
         "SBERT",
         "Test Set",
         "0.9833",
         "0.9904",
         "0.978",
         "0.9842",
         "0.9717",
         "0.9725",
         "0.9717",
         "0.9713"
        ],
        [
         "58",
         "Multi-Task Learning",
         "DistilBERT",
         "Test Set",
         "0.975",
         "0.9749",
         "0.978",
         "0.9765",
         "0.9517",
         "0.9541",
         "0.9517",
         "0.9522"
        ],
        [
         "59",
         "Multi-Task Learning",
         "SBERT",
         "Test Set",
         "0.9783",
         "0.9811",
         "0.978",
         "0.9795",
         "0.9783",
         "0.9791",
         "0.9783",
         "0.9781"
        ]
       ],
       "shape": {
        "columns": 11,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>Type</th>\n",
       "      <th>y1_Accuracy</th>\n",
       "      <th>y1_Precision</th>\n",
       "      <th>y1_Recall</th>\n",
       "      <th>y1_F1_Score</th>\n",
       "      <th>y2_Accuracy</th>\n",
       "      <th>y2_Precision</th>\n",
       "      <th>y2_Recall</th>\n",
       "      <th>y2_F1_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SVM</td>\n",
       "      <td>SBERT</td>\n",
       "      <td>Test Set</td>\n",
       "      <td>0.9833</td>\n",
       "      <td>0.9904</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.9842</td>\n",
       "      <td>0.9717</td>\n",
       "      <td>0.9725</td>\n",
       "      <td>0.9717</td>\n",
       "      <td>0.9713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Multi-Task Learning</td>\n",
       "      <td>DistilBERT</td>\n",
       "      <td>Test Set</td>\n",
       "      <td>0.9750</td>\n",
       "      <td>0.9749</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.9765</td>\n",
       "      <td>0.9517</td>\n",
       "      <td>0.9541</td>\n",
       "      <td>0.9517</td>\n",
       "      <td>0.9522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>Multi-Task Learning</td>\n",
       "      <td>SBERT</td>\n",
       "      <td>Test Set</td>\n",
       "      <td>0.9783</td>\n",
       "      <td>0.9811</td>\n",
       "      <td>0.978</td>\n",
       "      <td>0.9795</td>\n",
       "      <td>0.9783</td>\n",
       "      <td>0.9791</td>\n",
       "      <td>0.9783</td>\n",
       "      <td>0.9781</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Algorithm   Embedding      Type  y1_Accuracy  y1_Precision  \\\n",
       "19                  SVM       SBERT  Test Set       0.9833        0.9904   \n",
       "58  Multi-Task Learning  DistilBERT  Test Set       0.9750        0.9749   \n",
       "59  Multi-Task Learning       SBERT  Test Set       0.9783        0.9811   \n",
       "\n",
       "    y1_Recall  y1_F1_Score  y2_Accuracy  y2_Precision  y2_Recall  y2_F1_Score  \n",
       "19      0.978       0.9842       0.9717        0.9725     0.9717       0.9713  \n",
       "58      0.978       0.9765       0.9517        0.9541     0.9517       0.9522  \n",
       "59      0.978       0.9795       0.9783        0.9791     0.9783       0.9781  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_result = pd.read_csv(\"results.csv\")\n",
    "# Get only the SVM with SBERT, and Multi-Task Learning with SBERT and DistilBERT\n",
    "original_result = original_result[\n",
    "    original_result[\"Type\"] == \"Test Set\"\n",
    "]\n",
    "original_result = original_result[\n",
    "    original_result[\"Algorithm\"].isin(\n",
    "        [\"SVM\", \"Multi-Task Learning\"]\n",
    "    )\n",
    "]\n",
    "original_result = original_result[\n",
    "    original_result[\"Embedding\"].isin(\n",
    "        [\"SBERT\", \"DistilBERT\"]\n",
    "    )\n",
    "]\n",
    "\n",
    "# Remove SVM with DistilBERT\n",
    "original_result = original_result[\n",
    "    ~((original_result[\"Algorithm\"] == \"SVM\") & (original_result[\"Embedding\"] == \"DistilBERT\"))\n",
    "]\n",
    "\n",
    "original_result.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm        object\n",
      "Embedding        object\n",
      "Type             object\n",
      "y1_Accuracy     float64\n",
      "y1_Precision    float64\n",
      "y1_Recall       float64\n",
      "y1_F1_Score     float64\n",
      "y2_Accuracy     float64\n",
      "y2_Precision    float64\n",
      "y2_Recall       float64\n",
      "y2_F1_Score     float64\n",
      "dtype: object\n",
      "Algorithm        object\n",
      "Embedding        object\n",
      "Type             object\n",
      "y1_Accuracy     float64\n",
      "y1_Precision    float64\n",
      "y1_Recall       float64\n",
      "y1_F1_Score     float64\n",
      "y2_Accuracy     float64\n",
      "y2_Precision    float64\n",
      "y2_Recall       float64\n",
      "y2_F1_Score     float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(original_result.dtypes)\n",
    "print(result.dtypes)\n",
    "original_result = original_result.reset_index(drop=True)\n",
    "result = result.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "Algorithm",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "Embedding",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "y1_Accuracy_diff",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "y1_Precision_diff",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "y1_Recall_diff",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "y1_F1_Score_diff",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "y2_Accuracy_diff",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "y2_Precision_diff",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "y2_Recall_diff",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "y2_F1_Score_diff",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "4246972d-3327-481c-a6b8-a951b146fe20",
       "rows": [
        [
         "0",
         "SVM",
         "SBERT",
         "+0.17%",
         "+0.32%",
         "-0.00%",
         "+0.16%",
         "+0.85%",
         "+0.81%",
         "+0.85%",
         "+0.87%"
        ],
        [
         "1",
         "Multi-Task Learning",
         "DistilBERT",
         "-0.68%",
         "+0.91%",
         "-2.25%",
         "-0.70%",
         "+0.35%",
         "+0.15%",
         "+0.35%",
         "+0.28%"
        ],
        [
         "2",
         "Multi-Task Learning",
         "SBERT",
         "+0.68%",
         "+0.96%",
         "+0.32%",
         "+0.64%",
         "-0.17%",
         "-0.18%",
         "-0.17%",
         "-0.18%"
        ]
       ],
       "shape": {
        "columns": 10,
        "rows": 3
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Algorithm</th>\n",
       "      <th>Embedding</th>\n",
       "      <th>y1_Accuracy_diff</th>\n",
       "      <th>y1_Precision_diff</th>\n",
       "      <th>y1_Recall_diff</th>\n",
       "      <th>y1_F1_Score_diff</th>\n",
       "      <th>y2_Accuracy_diff</th>\n",
       "      <th>y2_Precision_diff</th>\n",
       "      <th>y2_Recall_diff</th>\n",
       "      <th>y2_F1_Score_diff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>SBERT</td>\n",
       "      <td>+0.17%</td>\n",
       "      <td>+0.32%</td>\n",
       "      <td>-0.00%</td>\n",
       "      <td>+0.16%</td>\n",
       "      <td>+0.85%</td>\n",
       "      <td>+0.81%</td>\n",
       "      <td>+0.85%</td>\n",
       "      <td>+0.87%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Multi-Task Learning</td>\n",
       "      <td>DistilBERT</td>\n",
       "      <td>-0.68%</td>\n",
       "      <td>+0.91%</td>\n",
       "      <td>-2.25%</td>\n",
       "      <td>-0.70%</td>\n",
       "      <td>+0.35%</td>\n",
       "      <td>+0.15%</td>\n",
       "      <td>+0.35%</td>\n",
       "      <td>+0.28%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Multi-Task Learning</td>\n",
       "      <td>SBERT</td>\n",
       "      <td>+0.68%</td>\n",
       "      <td>+0.96%</td>\n",
       "      <td>+0.32%</td>\n",
       "      <td>+0.64%</td>\n",
       "      <td>-0.17%</td>\n",
       "      <td>-0.18%</td>\n",
       "      <td>-0.17%</td>\n",
       "      <td>-0.18%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Algorithm   Embedding y1_Accuracy_diff y1_Precision_diff  \\\n",
       "0                  SVM       SBERT           +0.17%            +0.32%   \n",
       "1  Multi-Task Learning  DistilBERT           -0.68%            +0.91%   \n",
       "2  Multi-Task Learning       SBERT           +0.68%            +0.96%   \n",
       "\n",
       "  y1_Recall_diff y1_F1_Score_diff y2_Accuracy_diff y2_Precision_diff  \\\n",
       "0         -0.00%           +0.16%           +0.85%            +0.81%   \n",
       "1         -2.25%           -0.70%           +0.35%            +0.15%   \n",
       "2         +0.32%           +0.64%           -0.17%            -0.18%   \n",
       "\n",
       "  y2_Recall_diff y2_F1_Score_diff  \n",
       "0         +0.85%           +0.87%  \n",
       "1         +0.35%           +0.28%  \n",
       "2         -0.17%           -0.18%  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate percentage differences\n",
    "diff_df = pd.DataFrame()\n",
    "diff_df[\"Algorithm\"] = result[\"Algorithm\"]\n",
    "diff_df[\"Embedding\"] = result[\"Embedding\"]\n",
    "\n",
    "# List of metrics to compare\n",
    "metrics = [\n",
    "    \"y1_Accuracy\",\n",
    "    \"y1_Precision\",\n",
    "    \"y1_Recall\",\n",
    "    \"y1_F1_Score\",\n",
    "    \"y2_Accuracy\",\n",
    "    \"y2_Precision\",\n",
    "    \"y2_Recall\",\n",
    "    \"y2_F1_Score\",\n",
    "]\n",
    "\n",
    "for metric in metrics:\n",
    "    diff_df[f\"{metric}_diff\"] = (\n",
    "        (result[metric] - original_result[metric]) / original_result[metric] * 100\n",
    "    ).round(2)\n",
    "\n",
    "# Add '%' symbol and format the output\n",
    "for col in diff_df.columns:\n",
    "    if col.endswith(\"_diff\"):\n",
    "        diff_df[col] = diff_df[col].apply(\n",
    "            lambda x: f\"{x:+.2f}%\" if not pd.isna(x) else \"N/A\"\n",
    "        )\n",
    "\n",
    "\n",
    "diff_df.to_csv(\"tuning_diff_results.csv\", index=False)\n",
    "\n",
    "diff_df.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
